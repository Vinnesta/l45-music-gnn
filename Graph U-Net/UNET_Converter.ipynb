{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyNI5I1L142Mw6E8cJUEScqn"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import time as TimeLib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch_scatter import scatter\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import fluidsynth\n",
    "import mido\n",
    "import pretty_midi\n",
    "import networkx as nx\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from pprint import pprint\n",
    "\n",
    "NORMAL_GRAPH = 89\n",
    "MINI_GRAPH = 21\n",
    "SEQ_FEATURE_LENGTH = 20\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "id": "qyzr3bRjoHR-"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs:  1\n",
      "GPU  0  name:  NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Get the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Print the number of available GPUs\n",
    "print(\"Number of available GPUs: \", num_gpus)\n",
    "\n",
    "# Print the name of each GPU\n",
    "for i in range(num_gpus):\n",
    "    print(\"GPU \", i, \" name: \", torch.cuda.get_device_name(i))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# For storing experimental results over the course of the practical\n",
    "RESULTS = {}\n",
    "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0: \n",
      "0\n",
      "Track 1: \n",
      "15788\n",
      "[(51, 60, 1049), (51, 0, 93), (35, 44, 86), (51, 54, 9), (39, 55, 168), (35, 0, 32), (39, 0, 129), (42, 52, 2), (42, 0, 115), (52, 76, 32), (51, 0, 7), (47, 56, 9), (52, 0, 24), (37, 61, 149), (54, 68, 0), (47, 0, 16), (52, 77, 36), (54, 0, 58), (54, 51, 0), (52, 0, 8), (52, 60, 41), (47, 57, 22), (54, 0, 10), (47, 0, 94), (46, 58, 46), (46, 0, 174), (52, 0, 10), (37, 0, 3), (51, 68, 0), (44, 35, 34)]\n",
      "[(51, 1.6886551024520846, 10.53108590593801), (51, 0.0, 0.9336425064368302), (35, 1.2383470751315289, 0.863368339285671), (51, 1.5197895922068763, 0.09035250062291905), (39, 1.547933843914411, 1.6865800116278225), (35, 0.0, 0.32125333554815666), (39, 0.0, 1.2950525089285065), (42, 1.4635010887918067, 0.02007833347175979), (42, 0.0, 1.154504174626188), (52, 2.1389631297726406, 0.32125333554815666), (51, 0.0, 0.07027416715115926), (47, 1.5760780956219458, 0.09035250062291905), (52, 0.0, 0.24094000166111748), (37, 1.7167993541596194, 1.4958358436461043), (54, 1.9138091161123627, 0.0), (47, 0.0, 0.16062666777407833), (52, 2.167107381480175, 0.3614100024916762), (54, 0.0, 0.5822716706810339), (54, 1.435356837084272, 0.0), (52, 0.0, 0.08031333388703916), (52, 1.6886551024520846, 0.4116058361710757), (47, 1.6042223473294805, 0.22086166818935768), (54, 0.0, 0.10039166735879895), (47, 0.0, 0.9436816731727101), (46, 1.632366599037015, 0.46180166985047516), (46, 0.0, 1.7468150120431016), (52, 0.0, 0.10039166735879895), (37, 0.0, 0.030117500207639685), (51, 1.9138091161123627, 0.0), (44, 0.9850488097637161, 0.3413316690199164)]\n"
     ]
    }
   ],
   "source": [
    "# Load the MIDI file\n",
    "file = mido.MidiFile('example.midi')\n",
    "msg_cnt = 0\n",
    "data_tuples = []\n",
    "for i, track in enumerate(file.tracks):\n",
    "    print('Track {}: {}'.format(i, track.name))\n",
    "    other_time = 0\n",
    "    for msg in track:\n",
    "        other_time += msg.time\n",
    "        if msg.type == 'note_on':\n",
    "            note_tuple = (msg.note - 20, msg.velocity, other_time)\n",
    "            other_time = 0\n",
    "            data_tuples.append(note_tuple)\n",
    "            msg_cnt += 1\n",
    "    print(msg_cnt)\n",
    "\n",
    "velocity_values = [t[1] for t in data_tuples]\n",
    "timestep_values = [t[2] for t in data_tuples]\n",
    "\n",
    "velocity_mean = 0 #np.mean(velocity_values)\n",
    "velocity_std = np.std(velocity_values)\n",
    "timestep_mean = 0 #np.mean(timestep_values)\n",
    "timestep_std = np.std(timestep_values)\n",
    "print(data_tuples[:30])\n",
    "initial_data_tuples = data_tuples.copy()\n",
    "data_tuples = [(t[0], (t[1] - 0) / velocity_std, (t[2] - 0) / timestep_std) for t in data_tuples]\n",
    "print(data_tuples[:30])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def create_piano_graph(num_nodes):\n",
    "    edges = [(i, i + 1) for i in range(1, num_nodes - 1)] + [(i + 1, i) for i in range(1, num_nodes - 1)]\n",
    "    edges += [(0, i) for i in range(1, num_nodes)] + [(i, 0) for i in range(1, num_nodes)]\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long, device='cuda:0').t().contiguous()\n",
    "\n",
    "    edge_features = [1] * (len(edges) - 2 * (num_nodes - 1)) + [0] * (2 * (num_nodes - 1))\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float, device='cuda:0').view(-1, 1)\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "edge_index, edge_attr = create_piano_graph(NORMAL_GRAPH)\n",
    "edge_index_mini, edge_attr_mini = create_piano_graph(MINI_GRAPH)\n",
    "x = torch.zeros((len(data_tuples), NORMAL_GRAPH, SEQ_FEATURE_LENGTH), dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for i, (note, velocity, timestep) in enumerate(data_tuples):\n",
    "    if i > 0:\n",
    "        x[i, :, :-1] = x[i-1, :, 1:]  # Shift all rows one to the front\n",
    "        x[i, :, -1] = x[i-1, :, -1]\n",
    "    # Normalize velocity and timestep\n",
    "    x[i, note, -1] = velocity\n",
    "    x[i, 0, -1] = timestep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "graph_data_list = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    data = Data(x=x[i], edge_index=edge_index, edge_attr=edge_attr,  y=x[i].view(1, 89, 20))\n",
    "    graph_data_list.append(data)\n",
    "train_dataset = graph_data_list[:100]\n",
    "val_dataset = graph_data_list[100:125]\n",
    "test_dataset = graph_data_list[125:150]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, edge_dim, aggr='add'):\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, edge_attr):\n",
    "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        return self.mlp_msg(msg)\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
    "        return self.mlp_upd(upd_out)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "class MPNNModelEnDecoder(Module):\n",
    "    def __init__(self, num_layers, emb_dim, in_feature_dim, edge_dim, out_node_count, out_feature_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_feature_dim = out_feature_dim\n",
    "        self.out_node_count = out_node_count\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_feature_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> num_nodes * out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_node_count * out_feature_dim)\n",
    "        # n nodes in the graph\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.lin_in(data.x)  # (n, d_n) -> (n, d)\n",
    "        for conv in self.convs:\n",
    "            h = h + conv(h, data.edge_index, data.edge_attr)  # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "        h_graph = self.pool(h, data.batch)  # (n, d) -> (batch_size, d)\n",
    "\n",
    "        out_feature_matrix = self.lin_pred(h_graph)  # (batch_size, d) -> (batch_size, num_nodes * out_dim)\n",
    "        # Reshape the output to the desired matrix shape (batch_size, num_nodes, out_dim)\n",
    "        out_matrix = out_feature_matrix.view(-1, self.out_node_count, self.out_feature_dim)\n",
    "        out_matrix[:, 0, :] = self.relu(out_matrix[:, 0, :])\n",
    "\n",
    "        out_matrix[:, 1:, :] = out_matrix[:, 1:, :]\n",
    "        return out_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class GraphUNet(Module):\n",
    "    def __init__(self, num_layers=1, emb_dim=64, in_feature_dim=SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=NORMAL_GRAPH):\n",
    "        super().__init__()\n",
    "        self.encoder = MPNNModelEnDecoder(num_layers, emb_dim, in_feature_dim , edge_dim, out_node_count, out_feature_dim)\n",
    "        self.decoder = MPNNModelEnDecoder(num_layers, emb_dim, out_feature_dim, edge_dim, in_node_count , in_feature_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h_encoded = self.encoder(data)\n",
    "        batch_size = h_encoded.size(0)\n",
    "\n",
    "        # Create batch_decoded tensor\n",
    "        batch_decoded = torch.cat([torch.tensor([i] * MINI_GRAPH, dtype=torch.int64, device='cuda:0') for i in range(batch_size)], dim=0)\n",
    "\n",
    "        # Create new graph's edge attributes\n",
    "        edge_attr_batch = torch.cat([edge_attr_mini for _ in range(batch_size)], dim=0)\n",
    "\n",
    "        # Create new graph's edge indices\n",
    "        edge_index_batch = torch.cat([edge_index_mini + i * MINI_GRAPH for i in range(batch_size)], dim = 1)\n",
    "\n",
    "        data_decoded = Data(x=h_encoded.view(-1, self.encoder.out_feature_dim), batch=batch_decoded, edge_index=edge_index_batch, edge_attr=edge_attr_batch)\n",
    "\n",
    "        h_decoded = self.decoder(data_decoded)\n",
    "        return h_decoded, h_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 3. Initialize the model, optimizer, and loss function\n",
    "model = GraphUNet().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)[0]\n",
    "        loss = F.mse_loss(y_pred, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def eval(model, loader, device):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(data)[0]\n",
    "            # Mean Absolute Error using std (computed when preparing data)\n",
    "            error += (y_pred - data.y).abs().sum().item()\n",
    "    return error / len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100):\n",
    "\n",
    "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
    "\n",
    "    print(\"\\nModel architecture:\")\n",
    "    print(model)\n",
    "    total_param = 0\n",
    "    for param in model.parameters():\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print(f'Total parameters: {total_param}')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Adam optimizer with LR 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # LR scheduler which decays LR when validation metric doesn't improve\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
    "\n",
    "    print(\"\\nStart training:\")\n",
    "    best_val_error = None\n",
    "    perf_per_epoch = [] # Track Test/Val MAE vs. epoch (for plotting)\n",
    "    t = TimeLib.time()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # Call LR scheduler at start of each epoch\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Train model for one epoch, return avg. training loss\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        val_error = eval(model, val_loader, device)\n",
    "\n",
    "        if best_val_error is None or val_error <= best_val_error:\n",
    "            # Evaluate model on test set if validation metric improves\n",
    "            test_error = eval(model, test_loader, device)\n",
    "            best_val_error = val_error\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Print and track stats every 10 epochs\n",
    "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
    "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
    "\n",
    "        scheduler.step(val_error)\n",
    "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
    "\n",
    "    t = TimeLib.time() - t\n",
    "    train_time = t/60\n",
    "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
    "\n",
    "    return best_val_error, test_error, train_time, perf_per_epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for GraphUNet, training on 100 samples for 100 epochs.\n",
      "\n",
      "Model architecture:\n",
      "GraphUNet(\n",
      "  (encoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=32, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): MPNNLayer(emb_dim=32, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=32, out_features=420, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (decoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=32, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): MPNNLayer(emb_dim=32, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=32, out_features=1780, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      ")\n",
      "Total parameters: 87064\n",
      "\n",
      "Start training:\n",
      "Epoch: 010, LR: 0.001000, Loss: 0.0790781, Val MAE: 192.3377344, Test MAE: 218.4402344\n",
      "Epoch: 020, LR: 0.001000, Loss: 0.0710372, Val MAE: 149.7003027, Test MAE: 171.9776953\n",
      "Epoch: 030, LR: 0.001000, Loss: 0.0697418, Val MAE: 148.6887012, Test MAE: 177.4452148\n",
      "Epoch: 040, LR: 0.000900, Loss: 0.0693774, Val MAE: 145.2584863, Test MAE: 179.2151563\n",
      "Epoch: 050, LR: 0.000810, Loss: 0.0685538, Val MAE: 147.3062891, Test MAE: 179.2151563\n",
      "Epoch: 060, LR: 0.000729, Loss: 0.0673602, Val MAE: 142.7822461, Test MAE: 183.8625000\n",
      "Epoch: 070, LR: 0.000729, Loss: 0.0659696, Val MAE: 135.7960352, Test MAE: 178.8567187\n",
      "Epoch: 080, LR: 0.000656, Loss: 0.0650235, Val MAE: 142.0648242, Test MAE: 178.8567187\n",
      "Epoch: 090, LR: 0.000531, Loss: 0.0643980, Val MAE: 146.9870313, Test MAE: 178.8567187\n",
      "Epoch: 100, LR: 0.000478, Loss: 0.0640730, Val MAE: 146.8866211, Test MAE: 178.8567187\n",
      "\n",
      "Done! Training took 0.10 mins. Best validation MAE: 135.7960352, corresponding test MAE: 178.8567187.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alike\\AppData\\Local\\Temp\\ipykernel_4796\\3739639394.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "model = GraphUNet(num_layers=1, emb_dim=32, in_feature_dim = SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=89)\n",
    "model_name = type(model).__name__\n",
    "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
    "    model,\n",
    "    model_name,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100\n",
    ")\n",
    "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
    "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 8\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m      7\u001B[0m     output \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[1;32m----> 8\u001B[0m graph_output_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m())\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "graph_output_list = []\n",
    "\n",
    "# Process each data element and store the output\n",
    "for data in graph_data_list:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "    graph_output_list.append(output.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_tuples(x):\n",
    "    extracted_data_tuples = []\n",
    "    for i in range(0, len(x)):\n",
    "        if i > 0:\n",
    "            prev_x = x[i - 1].squeeze()\n",
    "        else:\n",
    "            prev_x = torch.zeros_like(x[i]).squeeze()\n",
    "        curr_x = x[i].squeeze()\n",
    "        diff_mask = torch.abs(prev_x[:, -1] - curr_x[:, -1])\n",
    "        mask = torch.zeros_like(diff_mask)\n",
    "        mask[1:] = 1  # exclude 0th index\n",
    "        masked_diff = diff_mask * mask  # apply the mask\n",
    "        changed_note = torch.argmax(masked_diff).item()\n",
    "        # Get the velocity and timestep\n",
    "        velocity = curr_x[changed_note, -1].item()\n",
    "        timestep = curr_x[0, -1].item()\n",
    "\n",
    "        extracted_data_tuples.append((changed_note, velocity, timestep))\n",
    "\n",
    "    return extracted_data_tuples\n",
    "all_data_tuples = []\n",
    "all_data_tuples = extract_tuples(graph_output_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data_tuples[0:5])\n",
    "print(all_data_tuples[0:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tuples_to_midi(data_tuples, filename, velocity_std, timestep_std):\n",
    "    # Initialize a new MIDI file and track\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    # Process tuples and add MIDI messages to the track\n",
    "    COUNTER = 0\n",
    "    for note, velocity, timestep in data_tuples:\n",
    "        # De-normalize velocity and timestep\n",
    "        velocity = round(velocity * velocity_std)\n",
    "        timestep = round(timestep * timestep_std)\n",
    "\n",
    "        ini_tuple = initial_data_tuples[COUNTER]\n",
    "\n",
    "        if note != ini_tuple[0] or velocity != ini_tuple[1] or timestep != ini_tuple[2]:\n",
    "            print(initial_data_tuples[COUNTER])\n",
    "            print(note, velocity, timestep)\n",
    "            print()\n",
    "        COUNTER+=1\n",
    "        # Adjust note range\n",
    "        note = note + 20\n",
    "\n",
    "        # Clamp values to the valid MIDI range\n",
    "        note = max(21, min(108, note))\n",
    "        velocity = max(0, min(127, velocity))\n",
    "        #velocity = 64\n",
    "\n",
    "        # Add MIDI messages to the track\n",
    "        track.append(Message('note_on', note=note, velocity=velocity, time=timestep))\n",
    "\n",
    "    # Save the MIDI file\n",
    "    midi_file.save(filename)\n",
    "tuples_to_midi(data_tuples, 'output.mid', velocity_std, timestep_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
