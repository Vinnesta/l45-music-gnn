{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyNI5I1L142Mw6E8cJUEScqn"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import time as TimeLib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch_scatter import scatter\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import fluidsynth\n",
    "import mido\n",
    "import pretty_midi\n",
    "import networkx as nx\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "NORMAL_GRAPH = 89\n",
    "MINI_GRAPH = 21\n",
    "SEQ_FEATURE_LENGTH = 20"
   ],
   "metadata": {
    "id": "qyzr3bRjoHR-"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs:  1\n",
      "GPU  0  name:  NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Get the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Print the number of available GPUs\n",
    "print(\"Number of available GPUs: \", num_gpus)\n",
    "\n",
    "# Print the name of each GPU\n",
    "for i in range(num_gpus):\n",
    "    print(\"GPU \", i, \" name: \", torch.cuda.get_device_name(i))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0: \n",
      "0\n",
      "Track 1: \n",
      "15788\n",
      "[(51, 60, 1049), (51, 0, 93), (35, 44, 86), (51, 54, 9), (39, 55, 168), (35, 0, 32), (39, 0, 129), (42, 52, 2), (42, 0, 115), (52, 76, 32), (51, 0, 7), (47, 56, 9), (52, 0, 24), (37, 61, 149), (54, 68, 0), (47, 0, 16), (52, 77, 36), (54, 0, 58), (54, 51, 0), (52, 0, 8), (52, 60, 41), (47, 57, 22), (54, 0, 10), (47, 0, 94), (46, 58, 46), (46, 0, 174), (52, 0, 10), (37, 0, 3), (51, 68, 0), (44, 35, 34)]\n",
      "[(51, 1.6886551024520846, 10.53108590593801), (51, 0.0, 0.9336425064368302), (35, 1.2383470751315289, 0.863368339285671), (51, 1.5197895922068763, 0.09035250062291905), (39, 1.547933843914411, 1.6865800116278225), (35, 0.0, 0.32125333554815666), (39, 0.0, 1.2950525089285065), (42, 1.4635010887918067, 0.02007833347175979), (42, 0.0, 1.154504174626188), (52, 2.1389631297726406, 0.32125333554815666), (51, 0.0, 0.07027416715115926), (47, 1.5760780956219458, 0.09035250062291905), (52, 0.0, 0.24094000166111748), (37, 1.7167993541596194, 1.4958358436461043), (54, 1.9138091161123627, 0.0), (47, 0.0, 0.16062666777407833), (52, 2.167107381480175, 0.3614100024916762), (54, 0.0, 0.5822716706810339), (54, 1.435356837084272, 0.0), (52, 0.0, 0.08031333388703916), (52, 1.6886551024520846, 0.4116058361710757), (47, 1.6042223473294805, 0.22086166818935768), (54, 0.0, 0.10039166735879895), (47, 0.0, 0.9436816731727101), (46, 1.632366599037015, 0.46180166985047516), (46, 0.0, 1.7468150120431016), (52, 0.0, 0.10039166735879895), (37, 0.0, 0.030117500207639685), (51, 1.9138091161123627, 0.0), (44, 0.9850488097637161, 0.3413316690199164)]\n"
     ]
    }
   ],
   "source": [
    "# Load the MIDI file\n",
    "file = mido.MidiFile('example.midi')\n",
    "msg_cnt = 0\n",
    "data_tuples = []\n",
    "for i, track in enumerate(file.tracks):\n",
    "    print('Track {}: {}'.format(i, track.name))\n",
    "    other_time = 0\n",
    "    for msg in track:\n",
    "        other_time += msg.time\n",
    "        if msg.type == 'note_on':\n",
    "            note_tuple = (msg.note - 20, msg.velocity, other_time)\n",
    "            other_time = 0\n",
    "            data_tuples.append(note_tuple)\n",
    "            msg_cnt += 1\n",
    "    print(msg_cnt)\n",
    "\n",
    "velocity_values = [t[1] for t in data_tuples]\n",
    "timestep_values = [t[2] for t in data_tuples]\n",
    "\n",
    "velocity_mean = 0 #np.mean(velocity_values)\n",
    "velocity_std = np.std(velocity_values)\n",
    "timestep_mean = 0 #np.mean(timestep_values)\n",
    "timestep_std = np.std(timestep_values)\n",
    "print(data_tuples[:30])\n",
    "initial_data_tuples = data_tuples.copy()\n",
    "data_tuples = [(t[0], (t[1] - 0) / velocity_std, (t[2] - 0) / timestep_std) for t in data_tuples]\n",
    "print(data_tuples[:30])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def create_piano_graph(num_nodes):\n",
    "    edges = [(i, i + 1) for i in range(1, num_nodes - 1)] + [(i + 1, i) for i in range(1, num_nodes - 1)]\n",
    "    edges += [(0, i) for i in range(1, num_nodes)] + [(i, 0) for i in range(1, num_nodes)]\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long, device='cuda:0').t().contiguous()\n",
    "\n",
    "    edge_features = [1] * (len(edges) - 2 * (num_nodes - 1)) + [0] * (2 * (num_nodes - 1))\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float, device='cuda:0').view(-1, 1)\n",
    "    print(edge_attr.shape)\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([350, 1])\n",
      "torch.Size([78, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "edge_index, edge_attr = create_piano_graph(NORMAL_GRAPH)\n",
    "edge_index_mini, edge_attr_mini = create_piano_graph(MINI_GRAPH)\n",
    "x = torch.zeros((len(data_tuples), NORMAL_GRAPH, SEQ_FEATURE_LENGTH), dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for i, (note, velocity, timestep) in enumerate(data_tuples):\n",
    "    if i > 0:\n",
    "        x[i, :, :-1] = x[i-1, :, 1:]  # Shift all rows one to the front\n",
    "        x[i, :, -1] = x[i-1, :, -1]\n",
    "    # Normalize velocity and timestep\n",
    "    x[i, note, -1] = velocity\n",
    "    x[i, 0, -1] = timestep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "graph_data_list = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    data = Data(x=x[i], edge_index=edge_index, edge_attr=edge_attr,  y=x[i].view(1, 89, 20))\n",
    "    graph_data_list.append(data)\n",
    "train_dataset = graph_data_list[:1000]\n",
    "val_dataset = graph_data_list[1000:1250]\n",
    "test_dataset = graph_data_list[1250:1500]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, edge_dim, aggr='add'):\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, edge_attr):\n",
    "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        return self.mlp_msg(msg)\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
    "        return self.mlp_upd(upd_out)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "class MPNNModelEnDecoder(Module):\n",
    "    def __init__(self, num_layers, emb_dim, in_feature_dim, edge_dim, out_node_count, out_feature_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_feature_dim = out_feature_dim\n",
    "        self.out_node_count = out_node_count\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_feature_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> num_nodes * out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_node_count * out_feature_dim)\n",
    "        # n nodes in the graph\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        print(\" THE NUMBER OF TIMES WE ARE HEREEEEEEEEEEE\")\n",
    "        h = self.lin_in(data.x)  # (n, d_n) -> (n, d)\n",
    "        print(data.edge_index.shape)\n",
    "        for conv in self.convs:\n",
    "            h = h + conv(h, data.edge_index, data.edge_attr)  # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "\n",
    "        print(\"we are here in pool:\")\n",
    "        h_graph = self.pool(h, data.batch)  # (n, d) -> (batch_size, d)\n",
    "        print(h_graph.shape)\n",
    "\n",
    "        out_feature_matrix = self.lin_pred(h_graph)  # (batch_size, d) -> (batch_size, num_nodes * out_dim)\n",
    "        print(\"o:\", out_feature_matrix.shape)\n",
    "        # Reshape the output to the desired matrix shape (batch_size, num_nodes, out_dim)\n",
    "        out_matrix = out_feature_matrix.view(-1, self.out_node_count, self.out_feature_dim)\n",
    "        out_matrix[:, 0, :] = self.relu(out_matrix[:, 0, :])\n",
    "\n",
    "        out_matrix[:, 1:, :] = out_matrix[:, 1:, :].clamp(0, 1)\n",
    "        return out_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# class Decoder(Module):\n",
    "#     def __init__(self, in_feature_dim=20, out_dim=20, in_nodes=10, out_nodes=89):\n",
    "#         super().__init__()\n",
    "#\n",
    "#         self.in_feature_dim = in_feature_dim\n",
    "#         self.out_dim = out_dim\n",
    "#         self.in_nodes = in_nodes\n",
    "#         self.out_nodes = out_nodes\n",
    "#\n",
    "#         self.fc1 = Linear(in_feature_dim * in_nodes, 256)\n",
    "#         self.fc2 = Linear(256, 512)\n",
    "#         self.fc3 = Linear(512, out_dim * out_nodes)\n",
    "#         self.relu = ReLU()\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, self.in_nodes * self.in_feature_dim)  # Flatten input matrix\n",
    "#         x = self.relu(self.fc1(x))\n",
    "#         x = self.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#\n",
    "#         # Reshape the output to the desired matrix shape (batch_size, out_nodes, out_dim)\n",
    "#         out_matrix = x.view(-1, self.out_nodes, self.out_dim)\n",
    "#\n",
    "#         return out_matrix\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class GraphUNet(Module):\n",
    "    def __init__(self, num_layers=4, emb_dim=64, in_feature_dim=SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=NORMAL_GRAPH):\n",
    "        super().__init__()\n",
    "        self.encoder = MPNNModelEnDecoder(num_layers, emb_dim, in_feature_dim , edge_dim, out_node_count, out_feature_dim)\n",
    "        self.decoder = MPNNModelEnDecoder(num_layers, emb_dim, out_feature_dim, edge_dim, in_node_count , in_feature_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h_encoded = self.encoder(data)\n",
    "        print(\"wtf?\",data.batch)\n",
    "\n",
    "        data_decoded = data.clone()\n",
    "        print(\":::::::\", data_decoded.edge_attr.shape)\n",
    "        data_decoded.x = h_encoded.view(-1, self.encoder.out_feature_dim)\n",
    "        data_decoded.batch = torch.tensor(([0] * MINI_GRAPH), dtype=torch.int64, device='cuda:0')\n",
    "        data_decoded.edge_index = edge_index_mini\n",
    "        data_decoded.edge_attr = edge_attr_mini\n",
    "\n",
    "        h_decoded = self.decoder(data_decoded)\n",
    "\n",
    "        return h_decoded\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# 3. Initialize the model, optimizer, and loss function\n",
    "model = GraphUNet().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(data)\n",
    "        loss = F.mse_loss(y_pred, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def eval(model, loader, device):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(data)\n",
    "            # Mean Absolute Error using std (computed when preparing data)\n",
    "            error += (y_pred * std - data.y * std).abs().sum().item()\n",
    "    return error / len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100):\n",
    "\n",
    "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
    "\n",
    "    print(\"\\nModel architecture:\")\n",
    "    print(model)\n",
    "    total_param = 0\n",
    "    for param in model.parameters():\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print(f'Total parameters: {total_param}')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Adam optimizer with LR 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # LR scheduler which decays LR when validation metric doesn't improve\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
    "\n",
    "    print(\"\\nStart training:\")\n",
    "    best_val_error = None\n",
    "    perf_per_epoch = [] # Track Test/Val MAE vs. epoch (for plotting)\n",
    "    t = TimeLib.time()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # Call LR scheduler at start of each epoch\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Train model for one epoch, return avg. training loss\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        val_error = eval(model, val_loader, device)\n",
    "\n",
    "        if best_val_error is None or val_error <= best_val_error:\n",
    "            # Evaluate model on test set if validation metric improves\n",
    "            test_error = eval(model, test_loader, device)\n",
    "            best_val_error = val_error\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Print and track stats every 10 epochs\n",
    "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
    "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
    "\n",
    "        scheduler.step(val_error)\n",
    "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
    "\n",
    "    t = TimeLib.time() - t\n",
    "    train_time = t/60\n",
    "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
    "\n",
    "    return best_val_error, test_error, train_time, perf_per_epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for GraphUNet, training on 1000 samples for 100 epochs.\n",
      "\n",
      "Model architecture:\n",
      "GraphUNet(\n",
      "  (encoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=64, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0-3): 4 x MPNNLayer(emb_dim=64, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=64, out_features=420, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (decoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=64, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0-3): 4 x MPNNLayer(emb_dim=64, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=64, out_features=1780, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      ")\n",
      "Total parameters: 348952\n",
      "\n",
      "Start training:\n",
      " THE NUMBER OF TIMES WE ARE HEREEEEEEEEEEE\n",
      "torch.Size([2, 350])\n",
      "we are here in pool:\n",
      "torch.Size([1, 64])\n",
      "o: torch.Size([1, 420])\n",
      "wtf? tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "::::::: torch.Size([350, 1])\n",
      " THE NUMBER OF TIMES WE ARE HEREEEEEEEEEEE\n",
      "torch.Size([2, 78])\n",
      "we are here in pool:\n",
      "torch.Size([1, 64])\n",
      "o: torch.Size([1, 1780])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 88, 20]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[41], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m GraphUNet(num_layers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, emb_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, in_feature_dim \u001B[38;5;241m=\u001B[39m SEQ_FEATURE_LENGTH, edge_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, out_node_count \u001B[38;5;241m=\u001B[39m MINI_GRAPH, out_feature_dim\u001B[38;5;241m=\u001B[39mSEQ_FEATURE_LENGTH, in_node_count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m89\u001B[39m)\n\u001B[0;32m      2\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(model)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m----> 3\u001B[0m best_val_error, test_error, train_time, perf_per_epoch \u001B[38;5;241m=\u001B[39m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\n\u001B[0;32m     10\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m RESULTS[model_name] \u001B[38;5;241m=\u001B[39m (best_val_error, test_error, train_time)\n\u001B[0;32m     12\u001B[0m df_temp \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(perf_per_epoch, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest MAE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVal MAE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "Cell \u001B[1;32mIn[40], line 29\u001B[0m, in \u001B[0;36mrun_experiment\u001B[1;34m(model, model_name, train_loader, val_loader, test_loader, n_epochs)\u001B[0m\n\u001B[0;32m     26\u001B[0m lr \u001B[38;5;241m=\u001B[39m scheduler\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mparam_groups[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlr\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     28\u001B[0m \u001B[38;5;66;03m# Train model for one epoch, return avg. training loss\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# Evaluate model on validation set\u001B[39;00m\n\u001B[0;32m     32\u001B[0m val_error \u001B[38;5;241m=\u001B[39m \u001B[38;5;28meval\u001B[39m(model, val_loader, device)\n",
      "Cell \u001B[1;32mIn[39], line 14\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, train_loader, optimizer, device)\u001B[0m\n\u001B[0;32m     12\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m model(data)\n\u001B[0;32m     13\u001B[0m loss \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mmse_loss(y_pred, data\u001B[38;5;241m.\u001B[39my)\n\u001B[1;32m---> 14\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m loss_all \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m data\u001B[38;5;241m.\u001B[39mnum_graphs\n\u001B[0;32m     16\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\torch\\_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    486\u001B[0m     )\n\u001B[1;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\pythonProject\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1, 88, 20]], which is output 0 of AsStridedBackward0, is at version 2; expected version 1 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "model = GraphUNet(num_layers=4, emb_dim=64, in_feature_dim = SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=89)\n",
    "model_name = type(model).__name__\n",
    "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
    "    model,\n",
    "    model_name,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100\n",
    ")\n",
    "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
    "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
    "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "graph_output_list = []\n",
    "\n",
    "# Process each data element and store the output\n",
    "for data in graph_data_list:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "    graph_output_list.append(output.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_tuples(x):\n",
    "    extracted_data_tuples = []\n",
    "    for i in range(0, len(x)):\n",
    "        if i > 0:\n",
    "            prev_x = x[i - 1].squeeze()\n",
    "        else:\n",
    "            prev_x = torch.zeros_like(x[i]).squeeze()\n",
    "        curr_x = x[i].squeeze()\n",
    "        diff_mask = torch.abs(prev_x[:, -1] - curr_x[:, -1])\n",
    "        mask = torch.zeros_like(diff_mask)\n",
    "        mask[1:] = 1  # exclude 0th index\n",
    "        masked_diff = diff_mask * mask  # apply the mask\n",
    "        changed_note = torch.argmax(masked_diff).item()\n",
    "        # Get the velocity and timestep\n",
    "        velocity = curr_x[changed_note, -1].item()\n",
    "        timestep = curr_x[0, -1].item()\n",
    "\n",
    "        extracted_data_tuples.append((changed_note, velocity, timestep))\n",
    "\n",
    "    return extracted_data_tuples\n",
    "all_data_tuples = []\n",
    "all_data_tuples = extract_tuples(graph_output_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(data_tuples[0:5])\n",
    "print(all_data_tuples[0:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tuples_to_midi(data_tuples, filename, velocity_std, timestep_std):\n",
    "    # Initialize a new MIDI file and track\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    # Process tuples and add MIDI messages to the track\n",
    "    COUNTER = 0\n",
    "    for note, velocity, timestep in data_tuples:\n",
    "        # De-normalize velocity and timestep\n",
    "        velocity = round(velocity * velocity_std)\n",
    "        timestep = round(timestep * timestep_std)\n",
    "\n",
    "        ini_tuple = initial_data_tuples[COUNTER]\n",
    "\n",
    "        if note != ini_tuple[0] or velocity != ini_tuple[1] or timestep != ini_tuple[2]:\n",
    "            print(initial_data_tuples[COUNTER])\n",
    "            print(note, velocity, timestep)\n",
    "            print()\n",
    "        COUNTER+=1\n",
    "        # Adjust note range\n",
    "        note = note + 20\n",
    "\n",
    "        # Clamp values to the valid MIDI range\n",
    "        note = max(21, min(108, note))\n",
    "        velocity = max(0, min(127, velocity))\n",
    "        #velocity = 64\n",
    "\n",
    "        # Add MIDI messages to the track\n",
    "        track.append(Message('note_on', note=note, velocity=velocity, time=timestep))\n",
    "\n",
    "    # Save the MIDI file\n",
    "    midi_file.save(filename)\n",
    "tuples_to_midi(data_tuples, 'output.mid', velocity_std, timestep_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
