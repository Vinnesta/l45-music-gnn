{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyNI5I1L142Mw6E8cJUEScqn"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time as TimeLib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch_scatter import scatter\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import fluidsynth\n",
    "import mido\n",
    "import pretty_midi\n",
    "import networkx as nx\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from pprint import pprint\n",
    "\n",
    "NORMAL_GRAPH = 89\n",
    "MINI_GRAPH = 21\n",
    "SEQ_FEATURE_LENGTH = 20\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "id": "qyzr3bRjoHR-"
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs:  1\n",
      "GPU  0  name:  NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Get the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Print the number of available GPUs\n",
    "print(\"Number of available GPUs: \", num_gpus)\n",
    "\n",
    "# Print the name of each GPU\n",
    "for i in range(num_gpus):\n",
    "    print(\"GPU \", i, \" name: \", torch.cuda.get_device_name(i))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# For storing experimental results over the course of the practical\n",
    "RESULTS = {}\n",
    "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# Load the MIDI file\n",
    "file = mido.MidiFile('example.midi')\n",
    "msg_cnt = 0\n",
    "data_tuples = []\n",
    "for i, track in enumerate(file.tracks):\n",
    "    other_time = 0\n",
    "    for msg in track:\n",
    "        other_time += msg.time\n",
    "        if msg.type == 'note_on':\n",
    "            note_tuple = (msg.note - 20, msg.velocity, other_time)\n",
    "            other_time = 0\n",
    "            data_tuples.append(note_tuple)\n",
    "            msg_cnt += 1\n",
    "\n",
    "velocity_values = [t[1] for t in data_tuples]\n",
    "timestep_values = [t[2] for t in data_tuples]\n",
    "\n",
    "velocity_mean = 0 #np.mean(velocity_values)\n",
    "velocity_std = 128\n",
    "timestep_mean = 0 #np.mean(timestep_values)\n",
    "timestep_std = np.std(timestep_values)\n",
    "data_tuples = [(t[0], (t[1] - 0) / velocity_std, (t[2] - 0) / timestep_std) for t in data_tuples]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def create_piano_graph(num_nodes):\n",
    "    edges = [(i, i + 1) for i in range(1, num_nodes - 1)] + [(i + 1, i) for i in range(1, num_nodes - 1)]\n",
    "    edges += [(0, i) for i in range(1, num_nodes)] + [(i, 0) for i in range(1, num_nodes)]\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long, device='cuda:0').t().contiguous()\n",
    "\n",
    "    edge_features = [1] * (len(edges) - 2 * (num_nodes - 1)) + [0] * (2 * (num_nodes - 1))\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float, device='cuda:0').view(-1, 1)\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "edge_index, edge_attr = create_piano_graph(NORMAL_GRAPH)\n",
    "edge_index_mini, edge_attr_mini = create_piano_graph(MINI_GRAPH)\n",
    "x = torch.zeros((len(data_tuples), NORMAL_GRAPH, SEQ_FEATURE_LENGTH), dtype=torch.float)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "for i, (note, velocity, timestep) in enumerate(data_tuples):\n",
    "    if i > 0:\n",
    "        x[i, :, :-1] = x[i-1, :, 1:]  # Shift all rows one to the front\n",
    "        x[i, :, -1] = x[i-1, :, -1]\n",
    "    # Normalize velocity and timestep\n",
    "    x[i, note, -1] = velocity\n",
    "    x[i, 0, -1] = timestep"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "graph_data_list = []\n",
    "\n",
    "for i in range(len(x)):\n",
    "    # Input is a 20 timestep matrix, the expected output is only the last step\n",
    "    data = Data(x=x[i], edge_index=edge_index, edge_attr=edge_attr,  y=x[i,:,-1])\n",
    "    graph_data_list.append(data)\n",
    "train_dataset = graph_data_list[:1000]\n",
    "val_dataset = graph_data_list[1000:1250]\n",
    "test_dataset = graph_data_list[1250:1500]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, edge_dim, aggr='add'):\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, edge_attr):\n",
    "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        return self.mlp_msg(msg)\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
    "        return self.mlp_upd(upd_out)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class MPNNModelEnDecoder(Module):\n",
    "    def __init__(self, in_node_count, num_layers, emb_dim, in_feature_dim, edge_dim, out_node_count, out_feature_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_feature_dim = out_feature_dim\n",
    "        self.out_node_count = out_node_count\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_feature_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> num_nodes * out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_node_count * out_feature_dim)\n",
    "        # n nodes in the graph\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.lin_in(data.x)  # (n, d_n) -> (n, d)\n",
    "        for conv in self.convs:\n",
    "            h = h + conv(h, data.edge_index, data.edge_attr)  # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "        h_graph = self.pool(h, data.batch)  # (n, d) -> (batch_size, d)\n",
    "\n",
    "        out_feature_matrix = self.lin_pred(h_graph)  # (batch_size, d) -> (batch_size, num_nodes * out_dim)\n",
    "        # Reshape the output to the desired matrix shape (batch_size, num_nodes, out_dim)\n",
    "        out_matrix = out_feature_matrix.view(-1, self.out_node_count, self.out_feature_dim)\n",
    "        out_matrix[:, 0, :] = self.relu(out_matrix[:, 0, :])\n",
    "\n",
    "        out_matrix[:, 1:, :] = out_matrix[:, 1:, :]\n",
    "        return out_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class GraphUNet(Module):\n",
    "    def __init__(self, num_layers=1, emb_dim=64, in_feature_dim=SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=NORMAL_GRAPH):\n",
    "        super().__init__()\n",
    "        self.encoder = MPNNModelEnDecoder( in_node_count, num_layers, emb_dim, in_feature_dim , edge_dim, out_node_count= out_node_count, out_feature_dim= out_feature_dim)\n",
    "        self.decoder = MPNNModelEnDecoder(out_node_count, num_layers, emb_dim, out_feature_dim, edge_dim, out_node_count= in_node_count , out_feature_dim= 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        h_encoded = self.encoder(data)\n",
    "        batch_size = h_encoded.size(0)\n",
    "\n",
    "        # Create batch_decoded tensor\n",
    "        batch_decoded = torch.cat([torch.tensor([i] * MINI_GRAPH, dtype=torch.int64, device='cuda:0') for i in range(batch_size)], dim=0)\n",
    "\n",
    "        # Create new graph's edge attributes\n",
    "        edge_attr_batch = torch.cat([edge_attr_mini for _ in range(batch_size)], dim=0)\n",
    "\n",
    "        # Create new graph's edge indices\n",
    "        edge_index_batch = torch.cat([edge_index_mini + i * MINI_GRAPH for i in range(batch_size)], dim = 1)\n",
    "\n",
    "        data_encoded = Data(x=h_encoded.view(-1, self.encoder.out_feature_dim), batch=batch_decoded, edge_index=edge_index_batch, edge_attr=edge_attr_batch)\n",
    "        h_decoded = self.decoder(data_encoded).squeeze(-1)\n",
    "        h_decoded[:, 1:] = self.sigmoid(h_decoded[:, 1:])\n",
    "        #.squeeze().view(-1)\n",
    "\n",
    "        return h_decoded, h_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "# 3. Initialize the model, optimizer, and loss function\n",
    "model = GraphUNet().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, encoded_matrix = model(data)\n",
    "        data.y = data.y.view(y_pred.shape[0],-1)\n",
    "        # Timestep loss\n",
    "        timestep_loss = F.mse_loss(y_pred[:, 0], data.y[:, 0])\n",
    "\n",
    "        key_on_loss = F.mse_loss(y_pred[:, 1:], data.y[:, 1:])\n",
    "        loss = timestep_loss * 1.5 + key_on_loss\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def eval(model, loader, device):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred, encoded_matrix = model(data)\n",
    "            data.y = data.y.view(y_pred.shape[0], -1)\n",
    "\n",
    "            # Mean Absolute Error for timesteps\n",
    "            timestep_error = (y_pred[:, 0] - data.y[:, 0]).abs().sum().item()\n",
    "\n",
    "            # Binary predictions for key velocities and their error\n",
    "            y_pred_binary = (y_pred[:, 1:] > 0.5).float()\n",
    "            key_velocity_error = (y_pred_binary - data.y[:, 1:]).abs().sum().item()\n",
    "\n",
    "            # Total error\n",
    "            error += timestep_error + key_velocity_error\n",
    "    return error / len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100):\n",
    "\n",
    "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
    "\n",
    "    print(\"\\nModel architecture:\")\n",
    "    print(model)\n",
    "    total_param = 0\n",
    "    for param in model.parameters():\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print(f'Total parameters: {total_param}')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Adam optimizer with LR 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # LR scheduler which decays LR when validation metric doesn't improve\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
    "\n",
    "    print(\"\\nStart training:\")\n",
    "    best_val_error = None\n",
    "    perf_per_epoch = [] # Track Test/Val MAE vs. epoch (for plotting)\n",
    "    t = TimeLib.time()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # Call LR scheduler at start of each epoch\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Train model for one epoch, return avg. training loss\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        val_error = eval(model, val_loader, device)\n",
    "\n",
    "        if best_val_error is None or val_error <= best_val_error:\n",
    "            # Evaluate model on test set if validation metric improves\n",
    "            test_error = eval(model, test_loader, device)\n",
    "            best_val_error = val_error\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Print and track stats every 10 epochs\n",
    "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
    "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
    "\n",
    "        scheduler.step(val_error)\n",
    "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
    "\n",
    "    t = TimeLib.time() - t\n",
    "    train_time = t/60\n",
    "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
    "\n",
    "    return best_val_error, test_error, train_time, perf_per_epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for GraphUNet, training on 1000 samples for 100 epochs.\n",
      "\n",
      "Model architecture:\n",
      "GraphUNet(\n",
      "  (encoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): MPNNLayer(emb_dim=256, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=256, out_features=420, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (decoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=256, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): MPNNLayer(emb_dim=256, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=256, out_features=89, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "Total parameters: 934653\n",
      "\n",
      "Start training:\n",
      "Epoch: 010, LR: 0.001000, Loss: 4.8084280, Val MAE: 20.2385804, Test MAE: 20.6020092\n",
      "Epoch: 020, LR: 0.000900, Loss: 4.7556068, Val MAE: 20.8210410, Test MAE: 20.5852491\n",
      "Epoch: 030, LR: 0.000810, Loss: 4.7501120, Val MAE: 20.3490316, Test MAE: 20.5350472\n",
      "Epoch: 040, LR: 0.000656, Loss: 4.7386027, Val MAE: 20.1953105, Test MAE: 20.5350472\n",
      "Epoch: 050, LR: 0.000590, Loss: 4.7140098, Val MAE: 20.3098725, Test MAE: 20.5350472\n",
      "Epoch: 060, LR: 0.000478, Loss: 4.7151422, Val MAE: 20.4046595, Test MAE: 20.5350472\n",
      "Epoch: 070, LR: 0.000387, Loss: 4.7125297, Val MAE: 21.0338149, Test MAE: 20.5350472\n",
      "Epoch: 080, LR: 0.000349, Loss: 4.7040646, Val MAE: 20.6011000, Test MAE: 20.5350472\n",
      "Epoch: 090, LR: 0.000282, Loss: 4.7025979, Val MAE: 20.8511719, Test MAE: 20.5350472\n",
      "Epoch: 100, LR: 0.000229, Loss: 4.7043901, Val MAE: 20.6523854, Test MAE: 20.5350472\n",
      "\n",
      "Done! Training took 0.86 mins. Best validation MAE: 20.1357641, corresponding test MAE: 20.5350472.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alike\\AppData\\Local\\Temp\\ipykernel_27868\\2263017003.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "model = GraphUNet(num_layers=1, emb_dim=256, in_feature_dim = SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=89)\n",
    "model_name = type(model).__name__\n",
    "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
    "    model,\n",
    "    model_name,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100\n",
    ")\n",
    "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test error\", \"Val error\", \"Epoch\", \"Model\"])\n",
    "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "graph_output_list = []\n",
    "\n",
    "# Process each data element and store the output\n",
    "for data in graph_data_list[:5000]:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data)[0]\n",
    "    graph_output_list.append(output.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def extract_tuples(pressed_keys):\n",
    "    extracted_data_tuples = []\n",
    "    prev_indices = []\n",
    "    for i in range(len(pressed_keys)):\n",
    "        pressed_keys[i] = pressed_keys[i].squeeze()\n",
    "        timestep = pressed_keys[i][0].item()\n",
    "        indices = torch.nonzero(pressed_keys[i][1:] > 1e-2).squeeze(-1).tolist()\n",
    "        extracted_data_tuples.append((0, 0, timestep))\n",
    "        for x in indices:\n",
    "            if x not in prev_indices:\n",
    "                extracted_data_tuples.append((x, round(pressed_keys[i][x].item() * 128), 0))\n",
    "        for x in prev_indices:\n",
    "            if x not in indices:\n",
    "                extracted_data_tuples.append((x, 0, 0))\n",
    "    return extracted_data_tuples\n",
    "extrated_tuples = extract_tuples(graph_output_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(51, 0.46875, 10.53108590593801), (51, 0.0, 0.9336425064368302), (35, 0.34375, 0.863368339285671), (51, 0.421875, 0.09035250062291905), (39, 0.4296875, 1.6865800116278225)]\n",
      "[(0, 0, 11.287561416625977), (24, 0, 0), (28, 0, 0), (29, 119, 0), (31, 0, 0)]\n"
     ]
    }
   ],
   "source": [
    "print(data_tuples[0:5])\n",
    "print(extrated_tuples[0:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def tuples_to_midi(data_tuples, filename, velocity_std, timestep_std):\n",
    "    # Initialize a new MIDI file and track\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    # Process tuples and add MIDI messages to the track\n",
    "    for note, velocity, timestep in data_tuples:\n",
    "        # De-normalize velocity and timestep\n",
    "        # velocity = round(velocity * velocity_std)\n",
    "        timestep = round(timestep * timestep_std)\n",
    "\n",
    "        # Adjust note range\n",
    "        note = note + 20\n",
    "\n",
    "        # Clamp values to the valid MIDI range\n",
    "        note = max(21, min(108, note))\n",
    "        velocity = max(0, min(127, velocity))\n",
    "        #velocity = 64\n",
    "\n",
    "        # Add MIDI messages to the track\n",
    "        track.append(Message('note_on', note=note, velocity=velocity, time=timestep))\n",
    "\n",
    "    # Save the MIDI file\n",
    "    midi_file.save(filename)\n",
    "tuples_to_midi(extrated_tuples, 'unet_output.mid', velocity_std, timestep_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
