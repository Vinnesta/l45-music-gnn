{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "authorship_tag": "ABX9TyNI5I1L142Mw6E8cJUEScqn"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time as TimeLib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
    "from torch_geometric.utils import add_self_loops, degree, remove_self_loops, to_dense_adj, dense_to_sparse\n",
    "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential\n",
    "from torch_scatter import scatter\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import Batch\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import fluidsynth\n",
    "import mido\n",
    "import pretty_midi\n",
    "import networkx as nx\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from pprint import pprint\n",
    "\n",
    "NORMAL_GRAPH = 89\n",
    "MINI_GRAPH = 11\n",
    "SEQ_FEATURE_LENGTH = 20\n",
    "BATCH_SIZE = 32\n",
    "BINARY_VELOCITY = False"
   ],
   "metadata": {
    "id": "qyzr3bRjoHR-"
   },
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs:  1\n",
      "GPU  0  name:  NVIDIA GeForce RTX 3070 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Get the number of available GPUs\n",
    "num_gpus = torch.cuda.device_count()\n",
    "\n",
    "# Print the number of available GPUs\n",
    "print(\"Number of available GPUs: \", num_gpus)\n",
    "\n",
    "# Print the name of each GPU\n",
    "for i in range(num_gpus):\n",
    "    print(\"GPU \", i, \" name: \", torch.cuda.get_device_name(i))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# For storing experimental results over the course of the practical\n",
    "RESULTS = {}\n",
    "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "def create_piano_graph(num_nodes):\n",
    "    edges = [(i, i + 1) for i in range(1, num_nodes - 1)] + [(i + 1, i) for i in range(1, num_nodes - 1)]\n",
    "    edges += [(0, i) for i in range(1, num_nodes)] + [(i, 0) for i in range(1, num_nodes)]\n",
    "    edge_index = torch.tensor(edges, dtype=torch.long, device='cuda:0').t().contiguous()\n",
    "\n",
    "    edge_features = [1] * (len(edges) - 2 * (num_nodes - 1)) + [0] * (2 * (num_nodes - 1))\n",
    "    edge_attr = torch.tensor(edge_features, dtype=torch.float, device='cuda:0').view(-1, 1)\n",
    "    return edge_index, edge_attr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "edge_index, edge_attr = create_piano_graph(NORMAL_GRAPH)\n",
    "edge_index_mini, edge_attr_mini = create_piano_graph(MINI_GRAPH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "# Load the MIDI file\n",
    "midi_files = os.listdir('mozart/')\n",
    "midi_files = [f for f in midi_files if f.endswith('.mid')]\n",
    "# Process each MIDI file and add to dataset\n",
    "file_to_tuples = []\n",
    "timestep_values = []\n",
    "for file_name in midi_files:\n",
    "    file_path = os.path.join('mozart', file_name)\n",
    "    file = mido.MidiFile(file_path)\n",
    "    tuples = []\n",
    "    for i, track in enumerate(file.tracks):\n",
    "        timestep = 0\n",
    "        for msg in track:\n",
    "            timestep += msg.time\n",
    "            if msg.type == 'note_on':\n",
    "                note_tuple = (msg.note - 20, msg.velocity, timestep)\n",
    "                timestep_values.append(timestep)\n",
    "                timestep = 0\n",
    "                tuples.append(note_tuple)\n",
    "    file_to_tuples.append(tuples)\n",
    "timestep_std = np.std(timestep_values)\n",
    "for i in range(len(file_to_tuples)):\n",
    "    file_to_tuples[i] = [(t[0], t[1]/128, t[2] /timestep_std) for t in file_to_tuples[i]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# dataset list\n",
    "graph_data_list = []\n",
    "unet_out_list = []\n",
    "for data_tuples in file_to_tuples:\n",
    "    x = torch.zeros((len(data_tuples), NORMAL_GRAPH, SEQ_FEATURE_LENGTH), dtype=torch.float)\n",
    "    for i, (note, velocity, timestep) in enumerate(data_tuples):\n",
    "        if i > 0:\n",
    "            x[i, :, :-1] = x[i-1, :, 1:]  # Shift all rows one to the front\n",
    "            x[i, :, -1] = x[i-1, :, -1]\n",
    "        # Normalize velocity and timestep\n",
    "        x[i, note, -1] = 1 if BINARY_VELOCITY else velocity\n",
    "        x[i, 0, -1] = timestep\n",
    "    for i in range(len(x)):\n",
    "        # Input is a 20 timestep matrix, the expected output is only the last step\n",
    "        data = Data(x=x[i], edge_index=edge_index, edge_attr=edge_attr,  y=x[i,:,-1])\n",
    "        graph_data_list.append(data)\n",
    "\n",
    "unet_out_list = []\n",
    "for data_tuples in file_to_tuples[:1]:\n",
    "    x = torch.zeros((len(data_tuples), NORMAL_GRAPH, SEQ_FEATURE_LENGTH), dtype=torch.float)\n",
    "    for i, (note, velocity, timestep) in enumerate(data_tuples):\n",
    "        if i > 0:\n",
    "            x[i, :, :-1] = x[i-1, :, 1:]  # Shift all rows one to the front\n",
    "            x[i, :, -1] = x[i-1, :, -1]\n",
    "        # Normalize velocity and timestep\n",
    "        x[i, note, -1] = 1 if BINARY_VELOCITY else velocity\n",
    "        x[i, 0, -1] = timestep\n",
    "    for i in range(len(x)):\n",
    "        # Input is a 20 timestep matrix, the expected output is only the last step\n",
    "        data = Data(x=x[i], edge_index=edge_index, edge_attr=edge_attr,  y=x[i,:,-1])\n",
    "        unet_out_list.append(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "random.shuffle(graph_data_list)\n",
    "train_dataset = graph_data_list[:3000]\n",
    "val_dataset = graph_data_list[3000:3500]\n",
    "test_dataset = graph_data_list[3500:4000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "class MPNNLayer(MessagePassing):\n",
    "    def __init__(self, emb_dim, edge_dim, aggr='add'):\n",
    "        # Set the aggregation function\n",
    "        super().__init__(aggr=aggr)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.mlp_msg = Sequential(\n",
    "            Linear(2*emb_dim + edge_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "        self.mlp_upd = Sequential(\n",
    "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
    "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
    "          )\n",
    "\n",
    "    def forward(self, h, edge_index, edge_attr):\n",
    "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr)\n",
    "        return out\n",
    "\n",
    "    def message(self, h_i, h_j, edge_attr):\n",
    "        msg = torch.cat([h_i, h_j, edge_attr], dim=-1)\n",
    "        return self.mlp_msg(msg)\n",
    "\n",
    "    def aggregate(self, inputs, index):\n",
    "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
    "\n",
    "    def update(self, aggr_out, h):\n",
    "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
    "        return self.mlp_upd(upd_out)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class MPNNModelEnDecoder(Module):\n",
    "    def __init__(self, in_node_count, num_layers, emb_dim, in_feature_dim, edge_dim, out_node_count, out_feature_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.out_feature_dim = out_feature_dim\n",
    "        self.out_node_count = out_node_count\n",
    "        # Linear projection for initial node features\n",
    "        # dim: d_n -> d\n",
    "        self.lin_in = Linear(in_feature_dim, emb_dim)\n",
    "\n",
    "        # Stack of MPNN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
    "\n",
    "        # Global pooling/readout function `R` (mean pooling)\n",
    "        # PyG handles the underlying logic via `global_mean_pool()`\n",
    "        self.pool = global_mean_pool\n",
    "\n",
    "        # Linear prediction head\n",
    "        # dim: d -> num_nodes * out_dim\n",
    "        self.lin_pred = Linear(emb_dim, out_node_count * out_feature_dim)\n",
    "        # n nodes in the graph\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, data):\n",
    "        h = self.lin_in(data.x)  # (n, d_n) -> (n, d)\n",
    "        for conv in self.convs:\n",
    "            h = h + conv(h, data.edge_index, data.edge_attr)  # (n, d) -> (n, d)\n",
    "            # Note that we add a residual connection after each MPNN layer\n",
    "        h_graph = self.pool(h, data.batch)  # (n, d) -> (batch_size, d)\n",
    "\n",
    "        out_feature_matrix = self.lin_pred(h_graph)  # (batch_size, d) -> (batch_size, num_nodes * out_dim)\n",
    "        # Reshape the output to the desired matrix shape (batch_size, num_nodes, out_dim)\n",
    "        out_matrix = out_feature_matrix.view(-1, self.out_node_count, self.out_feature_dim)\n",
    "        out_matrix[:, 0, :] = self.relu(out_matrix[:, 0, :])\n",
    "\n",
    "        out_matrix[:, 1:, :] = self.sigmoid(out_matrix[:, 1:, :])\n",
    "        return out_matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "class GraphUNet(Module):\n",
    "    def __init__(self, num_layers=1, emb_dim=64, in_feature_dim=SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=NORMAL_GRAPH):\n",
    "        super().__init__()\n",
    "        self.encoder = MPNNModelEnDecoder( in_node_count, num_layers, emb_dim, in_feature_dim , edge_dim, out_node_count= out_node_count, out_feature_dim= out_feature_dim)\n",
    "        self.decoder = MPNNModelEnDecoder(out_node_count, num_layers, emb_dim, out_feature_dim, edge_dim, out_node_count= in_node_count , out_feature_dim= 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        h_encoded = self.encoder(data)\n",
    "        batch_size = h_encoded.size(0)\n",
    "\n",
    "        # Create batch_decoded tensor\n",
    "        batch_decoded = torch.cat([torch.tensor([i] * MINI_GRAPH, dtype=torch.int64, device='cuda:0') for i in range(batch_size)], dim=0)\n",
    "\n",
    "        # Create new graph's edge attributes\n",
    "        edge_attr_batch = torch.cat([edge_attr_mini for _ in range(batch_size)], dim=0)\n",
    "\n",
    "        # Create new graph's edge indices\n",
    "        edge_index_batch = torch.cat([edge_index_mini + i * MINI_GRAPH for i in range(batch_size)], dim = 1)\n",
    "\n",
    "        data_encoded = Data(x=h_encoded.view(-1, self.encoder.out_feature_dim), batch=batch_decoded, edge_index=edge_index_batch, edge_attr=edge_attr_batch)\n",
    "        h_decoded = self.decoder(data_encoded).squeeze(-1)\n",
    "\n",
    "        return h_decoded, h_encoded"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# 3. Initialize the model, optimizer, and loss function\n",
    "model = GraphUNet().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, train_loader, optimizer, device):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred, encoded_matrix = model(data)\n",
    "        data.y = data.y.view(y_pred.shape[0], -1)\n",
    "\n",
    "        # Timestep loss\n",
    "        timestep_loss = F.mse_loss(y_pred[:, 0], data.y[:, 0])\n",
    "\n",
    "        # key velocity loss\n",
    "        key_on_loss = 0\n",
    "        if BINARY_VELOCITY:\n",
    "            key_on_loss = F.binary_cross_entropy(y_pred[:, 1:], data.y[:, 1:])\n",
    "        else:\n",
    "            key_on_loss = F.mse_loss(y_pred[:, 1:], data.y[:, 1:])\n",
    "\n",
    "        # total loss\n",
    "        loss = timestep_loss * 0.5 + key_on_loss * 4\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def eval(model, loader, device):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_pred, encoded_matrix = model(data)\n",
    "            data.y = data.y.view(y_pred.shape[0], -1)\n",
    "\n",
    "            # Mean Absolute Error for timesteps\n",
    "            timestep_error = (y_pred[:, 0] - data.y[:, 0]).abs().sum().item()\n",
    "\n",
    "            # predictions for key velocities and their error\n",
    "            key_velocity_error = 0 #(y_pred[:, 1:] - data.y[:, 1:]).abs().sum().item()\n",
    "\n",
    "            # Total error\n",
    "            error += timestep_error + key_velocity_error\n",
    "    return error / len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100):\n",
    "\n",
    "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
    "\n",
    "    print(\"\\nModel architecture:\")\n",
    "    print(model)\n",
    "    total_param = 0\n",
    "    for param in model.parameters():\n",
    "        total_param += np.prod(list(param.data.size()))\n",
    "    print(f'Total parameters: {total_param}')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Adam optimizer with LR 1e-3\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # LR scheduler which decays LR when validation metric doesn't improve\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
    "\n",
    "    print(\"\\nStart training:\")\n",
    "    best_val_error = None\n",
    "    perf_per_epoch = [] # Track Test/Val MAE vs. epoch (for plotting)\n",
    "    t = TimeLib.time()\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # Call LR scheduler at start of each epoch\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Train model for one epoch, return avg. training loss\n",
    "        loss = train(model, train_loader, optimizer, device)\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        val_error = eval(model, val_loader, device)\n",
    "\n",
    "        if best_val_error is None or val_error <= best_val_error:\n",
    "            # Evaluate model on test set if validation metric improves\n",
    "            test_error = eval(model, test_loader, device)\n",
    "            best_val_error = val_error\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            # Print and track stats every 10 epochs\n",
    "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
    "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
    "\n",
    "        scheduler.step(val_error)\n",
    "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
    "\n",
    "    t = TimeLib.time() - t\n",
    "    train_time = t/60\n",
    "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
    "\n",
    "    return best_val_error, test_error, train_time, perf_per_epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment for GraphUNet, training on 3000 samples for 100 epochs.\n",
      "\n",
      "Model architecture:\n",
      "GraphUNet(\n",
      "  (encoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=512, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): MPNNLayer(emb_dim=512, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=512, out_features=220, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (decoder): MPNNModelEnDecoder(\n",
      "    (lin_in): Linear(in_features=20, out_features=512, bias=True)\n",
      "    (convs): ModuleList(\n",
      "      (0): MPNNLayer(emb_dim=512, aggr=add)\n",
      "    )\n",
      "    (lin_pred): Linear(in_features=512, out_features=89, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total parameters: 3339061\n",
      "\n",
      "Start training:\n",
      "Epoch: 010, LR: 0.001000, Loss: 0.0397907, Val MAE: 0.0870311, Test MAE: 0.0706819\n",
      "Epoch: 020, LR: 0.000900, Loss: 0.0289852, Val MAE: 0.0812839, Test MAE: 0.0323401\n",
      "Epoch: 030, LR: 0.000729, Loss: 0.0143165, Val MAE: 0.0527058, Test MAE: 0.0323401\n",
      "Epoch: 040, LR: 0.000729, Loss: 0.0132677, Val MAE: 0.0432689, Test MAE: 0.0243038\n",
      "Epoch: 050, LR: 0.000590, Loss: 0.0153287, Val MAE: 0.0940965, Test MAE: 0.0243038\n",
      "Epoch: 060, LR: 0.000531, Loss: 0.0136447, Val MAE: 0.0408343, Test MAE: 0.0243038\n",
      "Epoch: 070, LR: 0.000430, Loss: 0.0106197, Val MAE: 0.0645681, Test MAE: 0.0243038\n",
      "Epoch: 080, LR: 0.000349, Loss: 0.0118259, Val MAE: 0.0630228, Test MAE: 0.0243038\n",
      "Epoch: 090, LR: 0.000314, Loss: 0.0093748, Val MAE: 0.0236550, Test MAE: 0.0174005\n",
      "Epoch: 100, LR: 0.000254, Loss: 0.0070952, Val MAE: 0.0468363, Test MAE: 0.0174005\n",
      "\n",
      "Done! Training took 3.28 mins. Best validation MAE: 0.0190953, corresponding test MAE: 0.0174005.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alike\\AppData\\Local\\Temp\\ipykernel_408\\3394304359.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "model = GraphUNet(num_layers=1, emb_dim=512, in_feature_dim = SEQ_FEATURE_LENGTH, edge_dim=1, out_node_count = MINI_GRAPH, out_feature_dim=SEQ_FEATURE_LENGTH, in_node_count=89)\n",
    "model_name = type(model).__name__\n",
    "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
    "    model,\n",
    "    model_name,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    test_loader,\n",
    "    n_epochs=100\n",
    ")\n",
    "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test error\", \"Val error\", \"Epoch\", \"Model\"])\n",
    "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for i in range(2,3):\n",
    "p = sns.lineplot(x=\"Epoch\", y=f\"Test error\", hue=\"Model\", data=DF_RESULTS)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "graph_output_list = []\n",
    "\n",
    "# Process each data element and store the output\n",
    "for data in unet_out_list[:100]:\n",
    "    data = data.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(data)[0]\n",
    "    graph_output_list.append(output.cpu())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "def extract_tuples(pressed_keys):\n",
    "    extracted_data_tuples = []\n",
    "    prev_indices = []\n",
    "    for i in range(len(pressed_keys)):\n",
    "        pressed_keys[i] = pressed_keys[i].squeeze()\n",
    "        timestep = pressed_keys[i][0].item()\n",
    "        indices = torch.where(pressed_keys[i][1:] > 1/100)[0].squeeze()\n",
    "        if indices.numel() == 1:\n",
    "            indices = [indices.add(1).tolist()]\n",
    "        else:\n",
    "            indices = indices.add(1).tolist()\n",
    "\n",
    "        # indices = torch.nonzero(pressed_keys[i][1:] > 1e-2).squeeze(-1).tolist()\n",
    "        extracted_data_tuples.append((0, 0, timestep))\n",
    "        for x in indices:\n",
    "            if x not in prev_indices:\n",
    "                if BINARY_VELOCITY and pressed_keys[i][x] < 0.5:\n",
    "                    continue\n",
    "                velocity = 64 if BINARY_VELOCITY else round(pressed_keys[i][x].item() * 128)\n",
    "                extracted_data_tuples.append((x, velocity, 0))\n",
    "        for x in prev_indices:\n",
    "            if x not in indices:\n",
    "                extracted_data_tuples.append((x, 0, 0))\n",
    "    return extracted_data_tuples\n",
    "extrated_tuples = extract_tuples(graph_output_list)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def tuples_to_midi(tuples, filename, timestep_std):\n",
    "    # Initialize a new MIDI file and track\n",
    "    midi_file = MidiFile()\n",
    "    track = MidiTrack()\n",
    "    midi_file.tracks.append(track)\n",
    "\n",
    "    # Process tuples and add MIDI messages to the track\n",
    "    for note, velocity, timestep in tuples:\n",
    "        # De-normalize velocity and timestep\n",
    "        # velocity = round(velocity * velocity_std)\n",
    "        timestep = round(timestep * timestep_std)\n",
    "\n",
    "        # Adjust note range\n",
    "        note = note + 20\n",
    "\n",
    "        # Clamp values to the valid MIDI range\n",
    "        note = max(21, min(108, note))\n",
    "        velocity = velocity * 10\n",
    "        velocity = max(0, min(127, velocity))\n",
    "        if BINARY_VELOCITY:\n",
    "            velocity = 64\n",
    "        # Add MIDI messages to the track\n",
    "        track.append(Message('note_on', note=note, velocity=velocity, time=timestep))\n",
    "\n",
    "    # Save the MIDI file\n",
    "    midi_file.save(filename)\n",
    "tuples_to_midi(extrated_tuples, 'unet_output.mid', timestep_std)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
