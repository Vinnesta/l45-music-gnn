{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-lZnwwf7NyU",
        "outputId": "942be48d-3571-41e5-e171-83116dd8b994"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\mange\\miniconda3\\envs\\music-gnn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import mido\n",
        "from utils.midi_tools02 import mid2arry, convert2binary, arry2mid\n",
        "from utils.data_processing import get_tonnetz_edge_index, slice_temporal_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmaG2s-J9BbZ"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0-D7kWW7wIw"
      },
      "source": [
        "## MIDI processing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mmrG_zz1729S"
      },
      "outputs": [],
      "source": [
        "def get_midi_timesteps(filename):\n",
        "    midi = mido.MidiFile(filename)\n",
        "    timesteps = 0\n",
        "    for track in midi.tracks:\n",
        "        for msg in track:\n",
        "            timesteps += msg.time\n",
        "    return timesteps\n",
        "\n",
        "def midi_to_tensor(filename, binary_velocity=False):\n",
        "    mid = mido.MidiFile(filename)\n",
        "    # Extract information about the notes being played\n",
        "    max_timesteps = get_midi_timesteps(filename)\n",
        "    tensor = np.zeros((max_timesteps, 128))\n",
        "    previous_note = [0] * 128\n",
        "    timesteps = 0\n",
        "    for track in mid.tracks:\n",
        "        for msg in track:\n",
        "            timesteps += msg.time\n",
        "            if msg.type == 'note_on':\n",
        "                tmp = previous_note[msg.note]\n",
        "                tensor[tmp:timesteps, msg.note] = tensor[tmp, msg.note]\n",
        "                if binary_velocity:\n",
        "                  tensor[timesteps, msg.note] = 1 if msg.velocity > 0 else 0\n",
        "                else:\n",
        "                  tensor[timesteps, msg.note] = msg.velocity\n",
        "                previous_note[msg.note] = timesteps\n",
        "            if msg.type == 'note_off':\n",
        "                tmp = previous_note[msg.note]\n",
        "                tensor[tmp:timesteps, msg.note] = tensor[tmp, msg.note]\n",
        "                tensor[timesteps, msg.note] = 0\n",
        "                previous_note[msg.note] = timesteps\n",
        "    return torch.from_numpy(tensor)\n",
        "\n",
        "def arry2mid(ary, tempo=500000):\n",
        "    new_ary = np.concatenate([np.array([[0] * 128]), np.array(ary)], axis=0)\n",
        "    mid_new = mido.MidiFile()\n",
        "    track = mido.MidiTrack()\n",
        "    mid_new.tracks.append(track)\n",
        "    track.append(mido.MetaMessage('set_tempo', tempo=tempo, time=0))\n",
        "    changes = new_ary[1:] - new_ary[:-1]\n",
        "    last_time = 0\n",
        "    for ch in changes:\n",
        "        if sum(ch) == 0:  # no change\n",
        "            last_time += 1\n",
        "        else:\n",
        "            on_notes = np.where(ch > 0)[0]\n",
        "            on_notes_velocity = ch[on_notes]\n",
        "            off_notes = np.where(ch < 0)[0]\n",
        "            first_ = True\n",
        "            for n, v in zip(on_notes, on_notes_velocity):\n",
        "                new_time = last_time if first_ else 0\n",
        "                track.append(mido.Message('note_on', note=int(n), velocity=int(v), time=int(new_time)))\n",
        "                first_ = False\n",
        "            for n in off_notes:\n",
        "                new_time = last_time if first_ else 0\n",
        "                track.append(mido.Message('note_off', note=int(n), velocity=0, time=int(new_time)))\n",
        "                first_ = False\n",
        "            last_time = 0\n",
        "    return mid_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq84Q7NB8TcH"
      },
      "source": [
        "## Tonnetz Adjancy matrix generating function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D-nSJY3O8Nsy"
      },
      "outputs": [],
      "source": [
        "# In Tonnetz, each node has six neighbours which have pitches of the following distances (in semi-tones)\n",
        "# E.g. C4 has neighbours F3, G#3, A3, D#4, E4, G4\n",
        "NEIGHBOUR_DISTANCES = [-7, -4, -3, 3, 4, 7]\n",
        "\n",
        "def create_tonnetz_adjacency_matrix(num_notes):\n",
        "  A = []\n",
        "\n",
        "  for i in range(num_notes):\n",
        "    row = torch.zeros(num_notes, dtype=torch.int)\n",
        "    for d in NEIGHBOUR_DISTANCES:\n",
        "      j = i+d\n",
        "      if j >= 0 and j < num_notes:\n",
        "        row[j] = 1\n",
        "    A.append(row)\n",
        "  return torch.stack(A)\n",
        "\n",
        "def get_edge_attributes(A):\n",
        "  # Returns edge attributes for the adjacency matrix `A`, \n",
        "  # where the edge attributes are a one-hot encoding for each type of edge\n",
        "  edge_index = A.to_sparse().indices()\n",
        "  edge_attr_raw = []\n",
        "  for i in range(edge_index.shape[1]):\n",
        "    distance = (edge_index[1][i] - edge_index[0][i]).item()\n",
        "    edge_attr_raw.append(NEIGHBOUR_DISTANCES.index(distance))\n",
        "  return F.one_hot(torch.tensor(edge_attr_raw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME2CAHxq8uLq"
      },
      "source": [
        "## Data processing helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BKqwyq5r8tZp"
      },
      "outputs": [],
      "source": [
        "import math, logging\n",
        "\n",
        "def calculate_compress_factor(file_name, desired_tpb):\n",
        "  mid = mido.MidiFile(file_name)\n",
        "  compress_factor = mid.ticks_per_beat / desired_tpb\n",
        "  if compress_factor % 1.0 != 0.0:\n",
        "    logging.warning(f\"compress_factor of {compress_factor} is not an integer, rounding up...\")\n",
        "  compress_factor = math.ceil(compress_factor)\n",
        "  return compress_factor\n",
        "\n",
        "def compress_tensor(tensor, file_name, method, desired_tpb=16):\n",
        "  '''\n",
        "  Reduces the fidelity of the musical tensor, i.e. merge multiple timesteps into one step\n",
        "\n",
        "  Args:\n",
        "    `tensor`: PyTorch tensor of shape (timesteps, num_notes)\n",
        "    `file_name`: path to the MIDI file\n",
        "    `method`: str in [\"max\", \"avg\", \"majority\"]\n",
        "    `desired_tpb`: desired ticks per beat for the tensor to be compressed to\n",
        "  '''\n",
        "  tensor_np = tensor.cpu().detach().cpu()\n",
        "  assert(len(tensor_np.shape) == 2)\n",
        "\n",
        "  compress_factor = calculate_compress_factor(file_name, desired_tpb)\n",
        "  compressed_vectors = []\n",
        "  length = tensor_np.shape[0]\n",
        "  for start in range(0, length, compress_factor):\n",
        "    end = min(start + compress_factor, length)\n",
        "    tensor_slice = tensor_np[start:end, :]\n",
        "    if (method == \"max\"):\n",
        "      raise NotImplementedError()\n",
        "    elif (method == \"avg\"):\n",
        "      raise NotImplementedError()\n",
        "    elif (method == \"majority\"):\n",
        "      majority = (end-start) / 2\n",
        "      majority_nonzeroes = np.count_nonzero(tensor_slice, axis=0) >= majority\n",
        "      compressed_vectors.append((majority_nonzeroes).astype(int))\n",
        "    else:\n",
        "      raise KeyError(f\"Unknown method {method}\")\n",
        "  return torch.tensor(np.array(compressed_vectors))\n",
        "\n",
        "def reduce_tensor(tensor, start_note, end_note):\n",
        "  '''\n",
        "  Args:\n",
        "    `tensor`: PyTorch tensor of shape (timesteps, num_notes)\n",
        "    `start_note`: note to start the tensor from (integer in 0-127)\n",
        "    `end_note`: note to end the tensor at (integer in 0-127)\n",
        "  '''\n",
        "  assert(end_note >= start_note)\n",
        "  return tensor[:, start_note:end_note+1]\n",
        "\n",
        "def uncompress_tensor(tensor, orig_tpb, compressed_tpb):\n",
        "  '''\n",
        "  Args:\n",
        "    `tensor`: PyTorch tensor of shape (timesteps, num_notes)\n",
        "    `orig_tpb`: ticks per beat of the original/generated MIDI file\n",
        "    `compressed_tpb`: ticks per beat used by the compressed `tensor`\n",
        "  '''\n",
        "  compress_factor = orig_tpb / compressed_tpb\n",
        "  if compress_factor % 1.0 != 0.0:\n",
        "    logging.warning(f\"compress_factor of {compress_factor} is not an integer, rounding up...\")\n",
        "  compress_factor = math.ceil(compress_factor)\n",
        "  # \"Stretch\" out the tensor using Kronecker product\n",
        "  return torch.kron(tensor, torch.ones((compress_factor, 1)))\n",
        "\n",
        "def unreduce_tensor(tensor, start_note, end_note):\n",
        "  '''\n",
        "  Expands out a reduced tensor to include all 128 notes in the MIDI range\n",
        "\n",
        "  Args:\n",
        "    `tensor`: PyTorch tensor of shape (timesteps, num_notes)\n",
        "    `start_note`: MIDI note that `tensor` starts from (integer in 0-127)\n",
        "    `end_note`: MIDI note that `tensor` ends at (integer in 0-127)\n",
        "  '''\n",
        "  assert(end_note >= start_note)\n",
        "  timesteps = tensor.shape[0]\n",
        "  low_notes = torch.zeros((timesteps, start_note))\n",
        "  high_notes = torch.zeros((timesteps, 127-end_note))\n",
        "  return torch.cat((low_notes, tensor.to(\"cpu\"), high_notes), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m6swA5zv86v7"
      },
      "outputs": [],
      "source": [
        "# function which takes music sequence and window size(history length) and return training data.\n",
        "# music = Time_step x Num_nodes\n",
        "def slice_temporal_data(music_seq,window_size=5):\n",
        "  return [[torch.transpose(music_seq[i:i+window_size],0,1),music_seq[i+window_size].reshape(-1,1)] for i in range(len(music_seq)-window_size)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSCQyHMh8_cf"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2C_jOnS9Ihv",
        "outputId": "af52301f-1975-4d1f-f979-71a45ec98d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_02_R3_2013_wav--1.midi', 'data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--1.midi', 'data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--2.midi', 'data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_07_R3_2013_wav--3.midi', 'data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--1.midi', 'data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--2.midi', 'data/2013\\\\ORIG-MIDI_01_7_10_13_Group_MID--AUDIO_08_R3_2013_wav--3.midi', 'data/2013\\\\ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--1.midi', 'data/2013\\\\ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--2.midi', 'data/2013\\\\ORIG-MIDI_01_7_6_13_Group__MID--AUDIO_01_R1_2013_wav--3.midi']\n"
          ]
        }
      ],
      "source": [
        "# Download and extract piano MIDI files from Maestro\n",
        "import os\n",
        "dir_to_scan = \"data/2013\"\n",
        "directory_files = os.listdir(dir_to_scan)\n",
        "data_files = []\n",
        "for file in directory_files:\n",
        "  data_files.append(os.path.join(dir_to_scan, file))\n",
        "print(data_files[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed5VIAheAn6e",
        "outputId": "0aa2b6a0-24d3-443a-e84e-e80e4e8ae3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91419 torch.Size([64, 32]) torch.Size([64, 1])\n"
          ]
        }
      ],
      "source": [
        "desired_tpb = 8\n",
        "\n",
        "num_files = 10\n",
        "window_size = desired_tpb * 4\n",
        "start_note = 33\n",
        "end_note = 96\n",
        "\n",
        "train_data = []\n",
        "for i, data_file in enumerate(data_files):\n",
        "  midi_tensor = midi_to_tensor(data_file, binary_velocity=True)\n",
        "  compressed_tensor = compress_tensor(midi_tensor, data_file, \"majority\", desired_tpb)\n",
        "  reduced_tensor = reduce_tensor(compressed_tensor, start_note, end_note)\n",
        "  train_data += slice_temporal_data(reduced_tensor.to(torch.float), window_size)\n",
        "  if i == num_files:\n",
        "    break\n",
        "print(len(train_data), train_data[0][0].shape, train_data[0][1].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp9Z44B_-KRE"
      },
      "source": [
        "# Prepare model trainig "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rEHG8HOCqf6"
      },
      "source": [
        "## create graph representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3JqrzX8-PzK",
        "outputId": "b9cb4470-a71b-4bd2-fde4-1d99255b928b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 64])\n",
            "torch.Size([356, 6])\n"
          ]
        }
      ],
      "source": [
        "new_num_notes = train_data[0][0].shape[0]\n",
        "A = create_tonnetz_adjacency_matrix(new_num_notes)\n",
        "edge_attr = get_edge_attributes(A)\n",
        "print(A.shape)\n",
        "print(edge_attr.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "812y9KPmCxIJ"
      },
      "source": [
        "## create data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTFnhU2eBbCF",
        "outputId": "70687f07-032f-47a8-ca8e-b3d8ad4a1b4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([91419, 64, 32])\n",
            "torch.Size([91419, 64])\n",
            "torch.Size([73135, 64, 32])\n",
            "torch.Size([73135, 64])\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "data_X = torch.stack([d[0] for d in train_data])\n",
        "print(data_X.shape)\n",
        "y = torch.stack([d[1] for d in train_data])\n",
        "data_Y = y.squeeze(-1)\n",
        "print(data_Y.shape)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_X.to(torch.float), data_Y, test_size=0.2, random_state=42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "valid_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 1\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hDx5UXs-C7nw"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNBPgThXC9mt",
        "outputId": "d0f6b951-4254-4208-a96a-1fd6f5657ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device is  cuda\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric_temporal.nn.recurrent import GConvLSTM\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device is \",device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsaFhODGGJpX"
      },
      "source": [
        "## model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ote6_xgTGM-S"
      },
      "outputs": [],
      "source": [
        "class SimpleSTGCN(nn.Module):\n",
        "    # input_dim = dim of node features\n",
        "    # output_dim = number of class which is ON/OFF\n",
        "    def __init__(self, adj_mat, edge_attrs, input_dim, hidden_dim=16, output_dim=2):\n",
        "        super(SimpleSTGCN, self).__init__()\n",
        "        self.adj_mat = adj_mat\n",
        "        self.edge_index = self.adj_mat.to_sparse().indices().to(device)\n",
        "        self.edge_weight = edge_attrs.to(device).to(float)\n",
        "        \n",
        "        # GCN layers\n",
        "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.gcn_conv1 = GConvLSTM(hidden_dim,hidden_dim,K=2)   # K=2 for 2-degree convolution (neighbor convolution)\n",
        "        self.linear3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.relu(self.linear2(x))\n",
        "        #print(x.shape)\n",
        "        h,c = self.gcn_conv1(x,self.edge_index)\n",
        "        #print(h.shape, c.shape)\n",
        "        x = F.relu(self.linear3(h))\n",
        "        x = self.linear4(x)\n",
        "        y_hat = x.squeeze(-1)\n",
        "        return y_hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpQ8slkGL05z",
        "outputId": "70e373a1-a18b-45a5-c9cb-7d019e45965c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 32])\n",
            "torch.Size([64, 16]) torch.Size([64, 16])\n"
          ]
        }
      ],
      "source": [
        "gcn_conv1 = GConvLSTM(32,16,K=2)\n",
        "edge_index = A.to_sparse().indices()\n",
        "#print(edge_index)\n",
        "for x,y in train_dataloader:\n",
        "  print(x[0].shape)\n",
        "  h,c = gcn_conv1(x[0],edge_index)\n",
        "  print(h.shape,c.shape)\n",
        "  break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Music"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## music create function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_music_tensor(net, seed, timesteps):\n",
        "  generated = seed\n",
        "  window_size = seed.shape[1]\n",
        "  for i in range(timesteps):\n",
        "    if i == 0:\n",
        "      pred = net(seed)\n",
        "    else:\n",
        "      pred = net(generated[:, -window_size:])\n",
        "    curr = (torch.sigmoid(pred) > 0.5).float()\n",
        "    generated = torch.cat((generated, curr.unsqueeze(1)), dim=1)\n",
        "  return generated\n",
        "\n",
        "def create_music(model, seed, new_timesteps, start_note, end_note, orig_tpb, compressed_tpb):\n",
        "  print(\"generating ...\")\n",
        "  generated_tensor = generate_music_tensor(model, seed, new_timesteps)\n",
        "  print(\"unreduce ...\")\n",
        "  generated_tensor_mod = unreduce_tensor(torch.transpose(generated_tensor, 0, 1), start_note, end_note)\n",
        "  print(\"uncompress ...\")\n",
        "  generated_tensor_mod = uncompress_tensor(generated_tensor_mod, orig_tpb, compressed_tpb)\n",
        "  return generated_tensor_mod"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## create music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_timesteps = 3000\n",
        "orig_tpb = 384\n",
        "compressed_tpb = desired_tpb\n",
        "\n",
        "net2 = SimpleSTGCN(A, edge_attr, window_size, output_dim=1)\n",
        "net2.load_state_dict(torch.load(\"model_params/Simple_GConvLSTM_model.net\"))\n",
        "net2 = net2.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generating ...\n",
            "unreduce ...\n",
            "uncompress ...\n",
            "torch.Size([145536, 128])\n"
          ]
        }
      ],
      "source": [
        "\n",
        "data, _ = next(iter(valid_dataloader))\n",
        "seed = data[0].to(device)\n",
        "generated = create_music(net2, seed, new_timesteps, start_note, end_note, orig_tpb, compressed_tpb)\n",
        "print(generated.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = generated.cpu().detach().numpy()\n",
        "mid = arry2mid(arr,tempo=5000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "mid.save(\"generated_music/sample_music_GConvLSTM_acc_0.4219.midi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MidiFile(type=1, ticks_per_beat=384, tracks=[\n",
              "  MidiTrack([\n",
              "    Message('note_on', channel=0, note=76, velocity=1, time=96),\n",
              "    Message('note_on', channel=0, note=83, velocity=0, time=0),\n",
              "    Message('note_on', channel=0, note=76, velocity=0, time=192),\n",
              "    Message('note_on', channel=0, note=82, velocity=1, time=0),\n",
              "    Message('note_on', channel=0, note=82, velocity=0, time=96),\n",
              "    Message('note_on', channel=0, note=67, velocity=0, time=48),\n",
              "    Message('note_on', channel=0, note=74, velocity=1, time=0),\n",
              "    Message('note_on', channel=0, note=69, velocity=1, time=192),\n",
              "    Message('note_on', channel=0, note=73, velocity=1, time=0),\n",
              "    Message('note_on', channel=0, note=74, velocity=0, time=0),\n",
              "    Message('note_on', channel=0, note=76, velocity=1, time=192),\n",
              "    Message('note_on', channel=0, note=73, velocity=0, time=96),\n",
              "    Message('note_on', channel=0, note=76, velocity=0, time=48),\n",
              "    Message('note_on', channel=0, note=77, velocity=1, time=0),\n",
              "    Message('note_on', channel=0, note=79, velocity=1, time=144),\n",
              "    Message('note_on', channel=0, note=77, velocity=0, time=48),\n",
              "    Message('note_on', channel=0, note=81, velocity=1, time=96),\n",
              "    Message('note_on', channel=0, note=79, velocity=0, time=48),\n",
              "    Message('note_on', channel=0, note=73, velocity=1, time=96),\n",
              "    Message('note_on', channel=0, note=81, velocity=0, time=0)])\n",
              "])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from utils.midi_tools01 import tensor_to_midi\n",
        "tensor_to_midi(generated,\"generated_music/sample_music_GConvLSTM_acc_0.4219.midi\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Piano roll view"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from utils.piano_roll_visualizer import piano_roll\n",
        "piano_roll(arr)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "g0-D7kWW7wIw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
